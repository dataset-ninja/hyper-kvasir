**HyperKvasir: The Largest Gastrointestinal Dataset** is a dataset for semantic segmentation and object detection tasks. It is used in the medical industry.

The dataset consists of 1000 images with 2133 labeled objects belonging to 2 different classes including *polyp* and *polyp_bbox*.

Images in the HyperKvasir dataset have pixel-level semantic segmentation annotations. Due to the nature of the semantic segmentation task, it can be automatically transformed into an object detection (bounding boxes for every object) task. All images are labeled (i.e. with annotations). There is 1 split in the dataset: *ds0* (1000 images). The dataset was released in 2020 by the [NO-SW-AU joint research group](https://www.nature.com/articles/s41597-020-00622-y#author-information).

Here is the visualized example grid with annotations:

<img src="https://github.com/dataset-ninja/hyper-kvasir/raw/main/visualizations/side_annotations_grid.png">
